{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning em Python (Colab): Cats vs Dogs (ou seu pr√≥prio dataset)\n\nEste notebook realiza **Transfer Learning** com TensorFlow/Keras usando **MobileNetV2** como base (pr√©-treinada no ImageNet).\nVoc√™ pode rodar com o dataset **Cats vs Dogs (TFDS)** ou adaptar para **sua pr√≥pria base** (duas classes).\n\n> Reposit√≥rio DIO: depois de finalizar, suba este notebook e o `README.md` para seu GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîß Checagem de ambiente (GPU) e vers√µes\nimport tensorflow as tf, sys, platform, os\n\nprint(\"TF:\", tf.__version__)\nprint(\"Python:\", sys.version.split()[0])\nprint(\"OS:\", platform.platform())\nprint(\"GPU dispon√≠vel:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîí Reprodutibilidade (definir sementes)\nimport random, numpy as np, tensorflow as tf\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Escolha a fonte dos dados\n\nVoc√™ tem **duas op√ß√µes**:\n\n1. **TFDS (recomendado):** baixa automaticamente `cats_vs_dogs`.\n2. **Pasta no Drive / upload pr√≥prio:** duas pastas, uma por classe, por ex.:\n```\ndataset/\n ‚îú‚îÄ cats/\n ‚îî‚îÄ dogs/\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 1A) Usar TFDS: Cats vs Dogs (autom√°tico)\n# Essa op√ß√£o n√£o exige download manual (apenas internet ativa no Colab).\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nfrom tensorflow import keras\n\nIMG_SIZE = 224\nBATCH_SIZE = 32\n\n(ds_train_full, ds_test_raw), ds_info = tfds.load(\n    \"cats_vs_dogs\",\n    split=[\"train[:90%]\", \"train[90%:]\"],  # TFDS n√£o traz test pronto; separamos parte final como \"teste\"\n    with_info=True,\n    as_supervised=True,\n)\n\n# Criar valida√ß√£o a partir do treino\ntrain_size = 0.8\nds_size = ds_info.splits[\"train\"].num_examples * 0.9  # pois usamos 90% como \"treino inteiro\"\nval_take = int((1 - train_size) * ds_size)\n\nds_val = ds_train_full.take(val_take)\nds_train = ds_train_full.skip(val_take)\n\nclass_names = [\"cat\", \"dog\"]\nnum_classes = 2\n\ndef preprocess(image, label):\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    image = image / 255.0\n    return image, label\n\nAUTOTUNE = tf.data.AUTOTUNE\n\nds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)                   .shuffle(2048, seed=SEED)                   .batch(BATCH_SIZE)                   .prefetch(AUTOTUNE)\n\nds_val = ds_val.map(preprocess, num_parallel_calls=AUTOTUNE)               .batch(BATCH_SIZE)               .prefetch(AUTOTUNE)\n\nds_test = ds_test_raw.map(preprocess, num_parallel_calls=AUTOTUNE)                     .batch(BATCH_SIZE)                     .prefetch(AUTOTUNE)\n\nprint(\"Batches (train/val/test):\", len(ds_train), len(ds_val), len(ds_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 1B) Usar seu pr√≥prio dataset (pasta no Drive) { run: \"false\" }\n# Descomente e ajuste o caminho do diret√≥rio com subpastas por classe.\n# Dica: monte o Drive no Colab: \n# from google.colab import drive\n# drive.mount('/content/drive')\n# DATA_DIR = \"/content/drive/MyDrive/datasets/cats_dogs\"  # ajuste aqui!\n\n# import tensorflow as tf\n# from tensorflow import keras\n# IMG_SIZE = 224\n# BATCH_SIZE = 32\n# seed = SEED\n\n# train_ds = keras.preprocessing.image_dataset_from_directory(\n#     DATA_DIR,\n#     validation_split=0.2,\n#     subset=\"training\",\n#     seed=seed,\n#     image_size=(IMG_SIZE, IMG_SIZE),\n#     batch_size=BATCH_SIZE,\n# )\n# val_ds = keras.preprocessing.image_dataset_from_directory(\n#     DATA_DIR,\n#     validation_split=0.2,\n#     subset=\"validation\",\n#     seed=seed,\n#     image_size=(IMG_SIZE, IMG_SIZE),\n#     batch_size=BATCH_SIZE,\n# )\n# class_names = train_ds.class_names\n# num_classes = len(class_names)\n\n# AUTOTUNE = tf.data.AUTOTUNE\n# ds_train = train_ds.prefetch(AUTOTUNE)\n# ds_val   = val_ds.prefetch(AUTOTUNE)\n\n# # Opcional: criar um pequeno conjunto de teste a partir da valida√ß√£o\n# ds_test = ds_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 2) Data Augmentation (recomendado para generaliza√ß√£o)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n], name=\"augmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 3) Constru√ß√£o do modelo (Transfer Learning com MobileNetV2)\nfrom tensorflow.keras import layers, models\n\nIMG_SIZE = 224\nbase = tf.keras.applications.MobileNetV2(\n    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    include_top=False,\n    weights=\"imagenet\"\n)\nbase.trainable = False  # Fase 1: congelado\n\ninputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nx = data_augmentation(inputs)\nx = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n\nx = base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.2)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\nmodel = models.Model(inputs, outputs)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\nmodel.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 4) Treinamento - Fase 1 (base congelada)\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nEPOCHS_1 = 5\n\nckpt_path = \"model_phase1.keras\"\ncallbacks = [\n    EarlyStopping(patience=2, restore_best_weights=True, monitor=\"val_accuracy\"),\n    ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\")\n]\n\nhistory1 = model.fit(\n    ds_train,\n    validation_data=ds_val,\n    epochs=EPOCHS_1,\n    callbacks=callbacks\n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 5) Fine-tuning - Fase 2 (descongelar parte da base)\n# Descongelar √∫ltimas camadas para refinar pesos pr√©-treinados.\nbase.trainable = True\n# \"Descongela\" a partir de um certo √≠ndice de camada para evitar overfitting/estabilidade\nfine_tune_at = len(base.layers) - 30\nfor layer in base.layers[:fine_tune_at]:\n    layer.trainable = False\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nEPOCHS_2 = 5\nckpt_path2 = \"model_phase2.keras\"\ncallbacks2 = [\n    EarlyStopping(patience=2, restore_best_weights=True, monitor=\"val_accuracy\"),\n    ModelCheckpoint(ckpt_path2, save_best_only=True, monitor=\"val_accuracy\")\n]\n\nhistory2 = model.fit(\n    ds_train,\n    validation_data=ds_val,\n    epochs=EPOCHS_2,\n    callbacks=callbacks2\n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 6) Curvas de treino (accuracy e loss)\nimport matplotlib.pyplot as plt\n\ndef plot_history(h, title_prefix=\"Phase\"):\n    acc = h.history.get(\"accuracy\", [])\n    val_acc = h.history.get(\"val_accuracy\", [])\n    loss = h.history.get(\"loss\", [])\n    val_loss = h.history.get(\"val_loss\", [])\n\n    # Accuracy\n    plt.figure()\n    plt.plot(acc, label=\"train_acc\")\n    plt.plot(val_acc, label=\"val_acc\")\n    plt.title(f\"{title_prefix} - Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()\n\n    # Loss\n    plt.figure()\n    plt.plot(loss, label=\"train_loss\")\n    plt.plot(val_loss, label=\"val_loss\")\n    plt.title(f\"{title_prefix} - Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\nplot_history(history1, \"Phase 1\")\nplot_history(history2, \"Phase 2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 7) Avalia√ß√£o no conjunto de teste\ntest_loss, test_acc = model.evaluate(ds_test)\nprint(\"Test accuracy:\", round(test_acc, 4), \"‚Äî loss:\", round(test_loss, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 8) Matriz de confus√£o e exemplos de previs√£o\nimport numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\ny_true = []\ny_pred = []\n\nfor images, labels in ds_test:\n    preds = model.predict(images, verbose=0)\n    y_true.extend(labels.numpy().tolist())\n    y_pred.extend(np.argmax(preds, axis=1).tolist())\n\nfrom sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(y_true, y_pred)\n\ndef plot_confusion_matrix(cm, classes):\n    plt.figure()\n    plt.imshow(cm, interpolation='nearest')\n    plt.title(\"Confusion Matrix\")\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.show()\n\nplot_confusion_matrix(cm, class_names)\nprint(classification_report(y_true, y_pred, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 9) Salvar modelo (Keras e TensorFlow Lite)\n# Salvar em formato Keras\nmodel.save(\"cats_dogs_transfer.keras\")\n\n# Exportar para SavedModel\nimport tensorflow as tf\ntf.saved_model.save(model, \"export_savedmodel\")\n\n# Converter para TFLite (opcional)\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"export_savedmodel\")\ntflite_model = converter.convert()\nwith open(\"model.tflite\", \"wb\") as f:\n    f.write(tflite_model)\n\nprint(\"Arquivos gerados: cats_dogs_transfer.keras, export_savedmodel/, model.tflite\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 10) (Opcional) Salvar no Google Drive\n# from google.colab import drive\n# drive.mount('/content/drive')\n# !mkdir -p \"/content/drive/MyDrive/transfer_learning\"\n# !cp -r cats_dogs_transfer.keras export_savedmodel model.tflite \"/content/drive/MyDrive/transfer_learning/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Como adaptar para **duas outras classes** (seu projeto)\n\n- Troque a fonte dos dados (se√ß√£o 1B) apontando para a pasta com **duas classes** (nomes das subpastas = r√≥tulos).\n- `num_classes` ser√° definido automaticamente a partir de `class_names` com `image_dataset_from_directory`.\n- Para base diferente, voc√™ pode substituir `MobileNetV2` por `EfficientNetB0`, `ResNet50`, etc.\n- Ajuste `fine_tune_at`, `EPOCHS_1`, `EPOCHS_2` e `learning_rate` conforme necess√°rio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refer√™ncias √∫teis\n- TFDS Cats vs Dogs: https://www.tensorflow.org/datasets/catalog/cats_vs_dogs  \n- Dataset (Microsoft Research download): https://www.microsoft.com/en-us/download/details.aspx?id=54765  \n- Exemplo de Transfer Learning (ml4a): https://colab.research.google.com/github/kylemath/ml4a-guides/blob/master/notebooks/transfer-learning.ipynb\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}